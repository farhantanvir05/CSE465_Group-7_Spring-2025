{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5SOENJ_zaCH",
        "outputId": "53b79001-fdce-4967-8dfb-fa0800b2ffc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of GPU:  1\n",
            "GPU Name:  NVIDIA A100-SXM4-40GB\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"Number of GPU: \", torch.cuda.device_count())\n",
        "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "WGktjF3wz3vT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/fracture_detection/MURA-v1.1.zip\"\n",
        "extract_path = \"/content/\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Unzipping completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLBZtRA_0KLh",
        "outputId": "38a780f2-25f1-45e3-a89c-68c4635573b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # 224x224x3 -> 224x224x32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # -> 112x112x32\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # -> 56x56x64\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 56 * 56, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "_cpZaauK6qfr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation_loss(student_logits, teacher_logits, labels, temperature=4.0, alpha=0.5):\n",
        "    # Hard label loss\n",
        "    bce_loss = nn.BCEWithLogitsLoss()(student_logits, labels)\n",
        "\n",
        "    # Soft label loss\n",
        "    teacher_probs = torch.sigmoid(teacher_logits / temperature)\n",
        "    student_probs = torch.sigmoid(student_logits / temperature)\n",
        "\n",
        "    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")(\n",
        "        torch.log(student_probs + 1e-8), teacher_probs\n",
        "    )\n",
        "\n",
        "    return alpha * bce_loss + (1 - alpha) * (temperature**2) * kl_loss\n"
      ],
      "metadata": {
        "id": "lPWJbTEl63M_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNTransformerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = torchvision.models.resnet50(pretrained=True)\n",
        "        self.cnn.fc = nn.Identity()\n",
        "\n",
        "        self.fc_proj = nn.Linear(2048, 768)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=768, nhead=8)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
        "\n",
        "        self.classifier = nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.fc_proj(x)\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.transformer(x)\n",
        "        x = x.squeeze(1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Q-6iFrIJ7cae"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "_LsxHKp77-g4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_paths_labels_from_csv(csv_file):\n",
        "    df = pd.read_csv(csv_file, header=None)\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        rel_path = row[0]\n",
        "        label = 1 if \"positive\" in rel_path.lower() else 0\n",
        "        full_path = os.path.join(\"/content\", rel_path)\n",
        "\n",
        "        if os.path.isfile(full_path):\n",
        "            image_paths.append(full_path)\n",
        "            labels.append(label)\n",
        "\n",
        "    return image_paths, labels\n",
        "\n"
      ],
      "metadata": {
        "id": "yV_bx19g8Fmp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "from glob import glob\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MURADataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "def load_paths_labels(base_dir):\n",
        "    image_paths, labels = [], []\n",
        "    for phase in [\"train\", \"valid\"]:\n",
        "        phase_dir = os.path.join(base_dir, phase)\n",
        "        for body_part in os.listdir(phase_dir):\n",
        "            body_part_dir = os.path.join(phase_dir, body_part)\n",
        "            if not os.path.isdir(body_part_dir):\n",
        "                continue\n",
        "            for patient in os.listdir(body_part_dir):\n",
        "                patient_dir = os.path.join(body_part_dir, patient)\n",
        "                if not os.path.isdir(patient_dir):\n",
        "                    continue\n",
        "                for study in os.listdir(patient_dir):\n",
        "                    study_dir = os.path.join(patient_dir, study)\n",
        "                    if not os.path.isdir(study_dir):\n",
        "                        continue\n",
        "                    label = 1 if \"positive\" in study.lower() else 0\n",
        "                    for img in glob(os.path.join(study_dir, \"*.png\")):\n",
        "                        image_paths.append(img)\n",
        "                        labels.append(label)\n",
        "    return image_paths, labels\n",
        "\n",
        "\n",
        "image_paths, labels = load_paths_labels(\"/content/MURA-v1.1\")\n",
        "labels = np.array(labels)\n",
        "\n",
        "# 5-fold cross-validation setup\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(image_paths)):\n",
        "    print(f\"\\n--- Fold {fold+1}/{k_folds} ---\")\n",
        "\n",
        "    train_paths = [image_paths[i] for i in train_idx]\n",
        "    val_paths = [image_paths[i] for i in val_idx]\n",
        "    train_labels = labels[train_idx]\n",
        "    val_labels = labels[val_idx]\n",
        "\n",
        "    train_dataset = MURADataset(train_paths, train_labels, transform=train_transform)\n",
        "    val_dataset = MURADataset(val_paths, val_labels, transform=val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snd8QpGT8SCD",
        "outputId": "d331bcc3-142f-4eca-aa91-798218b7df38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fold 1/5 ---\n",
            "\n",
            "--- Fold 2/5 ---\n",
            "\n",
            "--- Fold 3/5 ---\n",
            "\n",
            "--- Fold 4/5 ---\n",
            "\n",
            "--- Fold 5/5 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model = CNNTransformerModel().to(device)\n",
        "teacher_model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "teacher_model.eval()\n",
        "\n",
        "student_model = StudentCNN().to(device)\n",
        "optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-4)\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    student_model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device).unsqueeze(1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher_model(imgs)\n",
        "\n",
        "        student_logits = student_model(imgs)\n",
        "        loss = distillation_loss(student_logits, teacher_logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Distillation Loss = {total_loss / len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "662pmTep64Jr",
        "outputId": "7a53c42a-57a5-4784-a1c1-23bd568db011"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Distillation Loss = -0.2738\n",
            "Epoch 2: Distillation Loss = -0.3089\n",
            "Epoch 3: Distillation Loss = -0.3303\n",
            "Epoch 4: Distillation Loss = -0.3473\n",
            "Epoch 5: Distillation Loss = -0.3649\n",
            "Epoch 6: Distillation Loss = -0.3779\n",
            "Epoch 7: Distillation Loss = -0.3954\n",
            "Epoch 8: Distillation Loss = -0.4048\n",
            "Epoch 9: Distillation Loss = -0.4132\n",
            "Epoch 10: Distillation Loss = -0.4239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "student_model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device).unsqueeze(1)\n",
        "        outputs = student_model(imgs)\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "print(\"Student Model Evaluation:\")\n",
        "print(f\"Accuracy  : {accuracy_score(y_true, y_pred):.4f}\")\n",
        "print(f\"Precision : {precision_score(y_true, y_pred):.4f}\")\n",
        "print(f\"Recall    : {recall_score(y_true, y_pred):.4f}\")\n",
        "print(f\"F1 Score  : {f1_score(y_true, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu7ss1r4Beir",
        "outputId": "8bf38ef6-bc2d-4649-82b1-e5ae58c5a045"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Model Evaluation:\n",
            "Accuracy  : 0.4092\n",
            "Precision : 0.4067\n",
            "Recall    : 0.9997\n",
            "F1 Score  : 0.5782\n"
          ]
        }
      ]
    }
  ]
}