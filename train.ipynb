{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtobdJ1doSu0",
        "outputId": "70ed627d-aeb7-4530-99f4-f9a162bd257f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipping completed!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/fracture_detection/MURA-v1.1.zip\"\n",
        "extract_path = \"/content/\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Unzipping completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mmLkd_zwWLDh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import copy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIZTiGcMQPjF"
      },
      "source": [
        "Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "15H6C6ZRzdDw"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fvAL62fE9kEj"
      },
      "outputs": [],
      "source": [
        "!pip install -q timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DHvbjssDG1ma"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_paths_labels_from_csv(csv_file):\n",
        "    df = pd.read_csv(csv_file, header=None)\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        rel_path = row[0]\n",
        "        label = 1 if \"positive\" in rel_path.lower() else 0\n",
        "        full_path = os.path.join(\"/content\", rel_path)\n",
        "\n",
        "        if os.path.isfile(full_path):\n",
        "            image_paths.append(full_path)\n",
        "            labels.append(label)\n",
        "\n",
        "    return image_paths, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdwvfYDIKG6T",
        "outputId": "5559eae1-6695-4a75-b322-c8a7acb27d27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Fold 1/5 ---\n",
            "\n",
            "--- Fold 2/5 ---\n",
            "\n",
            "--- Fold 3/5 ---\n",
            "\n",
            "--- Fold 4/5 ---\n",
            "\n",
            "--- Fold 5/5 ---\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "from glob import glob\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MURADataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "def load_paths_labels(base_dir):\n",
        "    image_paths, labels = [], []\n",
        "    for phase in [\"train\", \"valid\"]:\n",
        "        phase_dir = os.path.join(base_dir, phase)\n",
        "        for body_part in os.listdir(phase_dir):\n",
        "            body_part_dir = os.path.join(phase_dir, body_part)\n",
        "            if not os.path.isdir(body_part_dir):\n",
        "                continue\n",
        "            for patient in os.listdir(body_part_dir):\n",
        "                patient_dir = os.path.join(body_part_dir, patient)\n",
        "                if not os.path.isdir(patient_dir):\n",
        "                    continue\n",
        "                for study in os.listdir(patient_dir):\n",
        "                    study_dir = os.path.join(patient_dir, study)\n",
        "                    if not os.path.isdir(study_dir):\n",
        "                        continue\n",
        "                    label = 1 if \"positive\" in study.lower() else 0\n",
        "                    for img in glob(os.path.join(study_dir, \"*.png\")):\n",
        "                        image_paths.append(img)\n",
        "                        labels.append(label)\n",
        "    return image_paths, labels\n",
        "\n",
        "\n",
        "image_paths, labels = load_paths_labels(\"/content/MURA-v1.1\")\n",
        "labels = np.array(labels)\n",
        "\n",
        "# 5-fold cross-validation setup\n",
        "k_folds = 5\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(image_paths)):\n",
        "    print(f\"\\n--- Fold {fold+1}/{k_folds} ---\")\n",
        "\n",
        "    train_paths = [image_paths[i] for i in train_idx]\n",
        "    val_paths = [image_paths[i] for i in val_idx]\n",
        "    train_labels = labels[train_idx]\n",
        "    val_labels = labels[val_idx]\n",
        "\n",
        "    train_dataset = MURADataset(train_paths, train_labels, transform=train_transform)\n",
        "    val_dataset = MURADataset(val_paths, val_labels, transform=val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hw5JjJHYK5LR"
      },
      "outputs": [],
      "source": [
        "class CNNTransformerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = torchvision.models.resnet50(pretrained=True)\n",
        "        self.cnn.fc = nn.Identity()\n",
        "\n",
        "        self.fc_proj = nn.Linear(2048, 768)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=768, nhead=8)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
        "\n",
        "        self.classifier = nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.fc_proj(x)\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.transformer(x)\n",
        "        x = x.squeeze(1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RyVVb0JhUhNu"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"The secret `HF_TOKEN` does not exist\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B26hz5ZLMMO",
        "outputId": "10ca17b4-30ed-4850-d012-e63d1d2c8e11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNNTransformerModel().to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "best_f1 = 0\n",
        "patience, patience_counter = 3, 0\n",
        "\n",
        "def train_one_epoch():\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device).unsqueeze(1)\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device).unsqueeze(1)\n",
        "            outputs = model(imgs)\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return acc, prec, rec, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzmhYlLhLhO6",
        "outputId": "745486c3-1a42-4110-d4d4-3cc7b8ffa709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss=0.5107, Acc=0.7897, Precision=0.7981, Recall=0.6506, F1=0.7168\n",
            "Epoch 2: Train Loss=0.4491, Acc=0.8073, Precision=0.7814, Recall=0.7346, F1=0.7572\n",
            "Epoch 3: Train Loss=0.4284, Acc=0.8188, Precision=0.8046, Recall=0.7358, F1=0.7687\n",
            "Epoch 4: Train Loss=0.4073, Acc=0.8171, Precision=0.8583, Recall=0.6625, F1=0.7478\n",
            "Epoch 5: Train Loss=0.3889, Acc=0.8141, Precision=0.7868, Recall=0.7486, F1=0.7673\n",
            "Epoch 6: Train Loss=0.3761, Acc=0.8271, Precision=0.8371, Recall=0.7172, F1=0.7725\n",
            "Epoch 7: Train Loss=0.3576, Acc=0.8238, Precision=0.8585, Recall=0.6817, F1=0.7600\n",
            "Epoch 8: Train Loss=0.3476, Acc=0.8086, Precision=0.8639, Recall=0.6319, F1=0.7299\n",
            "Epoch 9: Train Loss=0.3253, Acc=0.8165, Precision=0.7863, Recall=0.7575, F1=0.7716\n",
            "Early stopping!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_one_epoch()\n",
        "    acc, prec, rec, f1 = evaluate()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Acc={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(best_model_wts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qy_JTBW3z7k",
        "outputId": "53dd9837-bae5-4596-85e5-2462685fef02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧪 Test Evaluation:\n",
            "Accuracy  : 0.8274\n",
            "Precision : 0.8374\n",
            "Recall    : 0.7175\n",
            "F1 Score  : 0.7728\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load model definition here\n",
        "model = CNNTransformerModel().to(device)\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Assuming val_dataset\n",
        "test_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_paths = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (images, labels) in enumerate(test_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device).unsqueeze(1)\n",
        "\n",
        "        outputs = model(images)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs > 0.5).float()\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Metrics\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "prec = precision_score(all_labels, all_preds)\n",
        "rec = recall_score(all_labels, all_preds)\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "print(\" Test Evaluation:\")\n",
        "print(f\"Accuracy  : {acc:.4f}\")\n",
        "print(f\"Precision : {prec:.4f}\")\n",
        "print(f\"Recall    : {rec:.4f}\")\n",
        "print(f\"F1 Score  : {f1:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kl-EI7OPLe5"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
